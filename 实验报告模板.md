## 实验要求

1. 开发环境为 Ubuntu 18.04 和 PyTorch 1.8.2
2. 按照实验具体要求对网络进行修改，以提高网络的性能
3. 使用指定的数据集进行网络的训练
4. 保存实验结果，包括关键实验参数、最终模型、运行截图
5. 提交一份针对该实验的报告
6. 使用 QT 完成对算法模型的调用及结果读取
7. 对 ResNet 网络进行改进，加入 SE 注意力机制

## 实验目的

1. 掌握深度学习图像分类网络的基本原理和应用方法
2. 学习使用 PyTorch 框架进行模型训练和推理
3. 理解 ResNet 残差网络的结构特点
4. 掌握 SE (Squeeze-and-Excitation) 注意力机制的原理和实现
5. 学习使用 PyQt5 开发图形界面应用程序
6. 实现一个完整的垃圾分类系统

## 实验步骤

### 1. 环境配置与数据准备

**配置文件 (config.py):**
```python
net_name = 'resnet50'      # 使用 ResNet50 作为分类网络
num_classes = 6            # 6个垃圾类别
learning_rate = 2e-4       # 学习率
num_epochs = 200           # 训练轮数
batch_size = 32            # 批次大小
image_size = (224, 224)    # 输入图像尺寸
```

**数据集类别:**
- cardboard (纸板)
- glass (玻璃)
- metal (金属)
- paper (纸张)
- plastic (塑料)
- trash (其他垃圾)

### 2. 模型训练

运行训练命令:
```bash
python3 train.py
```

训练过程会:
- 加载 ResNet50 预训练权重
- 在垃圾分类数据集上进行微调
- 每 10 个 epoch 保存一次模型权重
- 训练结果保存在 `model_saved` 目录中

### 3. 模型测试

修改 `config.py` 中的模型路径后运行:
```bash
python3 demo.py -i 图片路径
```

### 4. QT 界面集成

**创建 demo1.py 供 QT 调用:**

改进了原有代码，主要修改:
1. 修复了垃圾分类逻辑错误 (原代码 `if a == 'x' or 'y'` 永远为 True)
2. 使用字典映射实现正确的分类逻辑
3. 封装为 `GarbageClassifier` 类，便于 QT 调用
4. 添加图像预处理的 Resize 操作，确保输入尺寸正确

```python
# 垃圾分类映射字典
GARBAGE_CATEGORIES = {
    'cardboard': '可回收物',
    'glass': '可回收物',
    'metal': '可回收物',
    'paper': '可回收物',
    'plastic': '可回收物',
    'trash': '其他垃圾',
    # ...
}

class GarbageClassifier:
    def classify(self, image_path):
        # 返回分类结果字典
        return {
            'class_name': '具体类别',
            'category': '垃圾大类',
            'confidence': 0.95,
            'success': True
        }
```

**QT 界面程序 (qt_garbage_classifier.py):**

实现功能:
- 图片选择和预览
- 垃圾分类识别
- 结果显示 (物品类别、垃圾大类、置信度)
- 不同垃圾类别使用不同颜色标识:
  - 可回收物: 蓝色
  - 厨余垃圾: 绿色
  - 有害垃圾: 红色
  - 其他垃圾: 灰色

运行 QT 界面:
```bash
python3 qt_garbage_classifier.py
```

### 5. SE 注意力机制实现 (思考题)

**SE (Squeeze-and-Excitation) 模块原理:**

SE 模块通过学习通道间的依赖关系来增强有用特征，抑制无用特征。

1. **Squeeze (压缩):** 使用全局平均池化将 H×W×C 的特征图压缩为 1×1×C
2. **Excitation (激励):** 通过两个全连接层学习通道权重
3. **Scale (缩放):** 用学习到的权重对原特征图进行通道加权

**SE 模块代码实现:**
```python
class SEBlock(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SEBlock, self).__init__()
        # 全局平均池化
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        # 两个全连接层
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        # Squeeze
        y = self.avg_pool(x).view(b, c)
        # Excitation
        y = self.fc(y).view(b, c, 1, 1)
        # Scale
        return x * y.expand_as(x)
```

**集成到 ResNet:**

在 ResNet 的 BasicBlock 和 Bottleneck 中添加 SE 模块:
```python
class Bottleneck(nn.Module):
    def __init__(self, ..., use_se=True, se_reduction=16):
        # ...
        if use_se:
            self.se = SEBlock(planes * self.expansion, se_reduction)

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)

        # 应用 SE 注意力
        if self.use_se:
            out = self.se(out)

        out += identity
        out = self.relu(out)
        return out
```

**使用带 SE 的 ResNet 训练:**

修改 `nets/NetsTorch.py`，添加 `use_se` 参数:
```python
model = NetsTorch(net_name='resnet50', pretrained=True, num_classes=6, use_se=True)
```

加载预训练权重时需要使用 `strict=False`:
```python
model.load_state_dict(state_dict, strict=False)
```

### 6. 实验截图

(请在此处添加以下截图)

1. 训练过程截图 (显示 loss 下降)
2. 测试结果截图 (使用 demo.py 测试)
3. QT 界面运行截图:
   - 选择图片界面
   - 分类结果显示界面

## 实验心得

1. **深度学习模型训练:** 通过本次实验，我深入理解了 ResNet 网络的残差连接设计，以及如何使用预训练权重进行迁移学习，大大加快了模型收敛速度。

2. **注意力机制:** SE 注意力机制通过建模通道间的依赖关系，能够自适应地调整特征图各通道的重要性权重，有效提升了模型的表达能力。

3. **代码调试:** 在实验过程中发现原有代码存在逻辑错误 (Python 中 `if a == 'x' or 'y'` 的写法)，通过修复这个问题，加深了对 Python 语法的理解。

4. **工程实践:** 通过 PyQt5 开发图形界面，学会了如何将深度学习模型与用户界面结合，构建一个完整的应用程序。

5. **模型部署:** 了解了模型从训练到部署的完整流程，包括模型保存、加载、推理等环节。

